{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.models import load_model\n",
    "\n",
    "import cv2\n",
    "import pynq.lib.dma\n",
    "from pynq import MMIO, PL, DefaultHierarchy, Overlay, Xlnk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FPGA_FULL_CONNECT_NET(DefaultHierarchy):\n",
    "    def __init__(self, description):\n",
    "        super().__init__(description)\n",
    "\n",
    "    def loadweight(self, W, index, IFMDim, OFMDim, PadDim):\n",
    "        KerDim = W.shape[2]\n",
    "        IFMCH = W.shape[1]\n",
    "        OFMCH = W.shape[0]\n",
    "        batch_size = 0\n",
    "        kernel_val = W.ravel() * 32768\n",
    "        kernel = np.append([index, batch_size, KerDim, IFMCH,\n",
    "                            IFMDim, OFMCH, OFMDim, PadDim], kernel_val)\n",
    "        kernel = kernel.astype(np.int16)\n",
    "        in_buffer = Xlnk().cma_array(shape=(kernel.shape[0]), dtype=np.int16)\n",
    "        out_buffer = Xlnk().cma_array(shape=(kernel.shape[0]), dtype=np.int16)\n",
    "        for i, v in enumerate(kernel):\n",
    "            in_buffer[i] = v\n",
    "        self.axi_dma_0.sendchannel.transfer(in_buffer)\n",
    "        self.axi_dma_0.recvchannel.transfer(out_buffer)\n",
    "        self.axi_dma_0.sendchannel.wait()\n",
    "        self.axi_dma_0.recvchannel.wait()\n",
    "\n",
    "    def execute(self, test_data, batch_size):\n",
    "        output_ch = 10\n",
    "        input_mat = test_data[0:batch_size]\n",
    "        input_val = input_mat.ravel()\n",
    "        input_val = np.append([0, batch_size, 1, 1, 28, 10, 1, 0], input_val)\n",
    "        input_val = input_val.astype(np.int16)\n",
    "        in_buffer = Xlnk().cma_array(\n",
    "            shape=(input_val.shape[0]), dtype=np.int16)\n",
    "        out_buffer = Xlnk().cma_array(\n",
    "            shape=(8 + output_ch * batch_size), dtype=np.int16)\n",
    "        for i, v in enumerate(input_val):\n",
    "            in_buffer[i] = v\n",
    "        start_time = time.process_time()\n",
    "        self.axi_dma_0.sendchannel.transfer(in_buffer)\n",
    "        self.axi_dma_0.recvchannel.transfer(out_buffer)\n",
    "        self.axi_dma_0.sendchannel.wait()\n",
    "        self.axi_dma_0.recvchannel.wait()\n",
    "        end_time = time.process_time()\n",
    "        print(\"Elapsed Test Time: \", end_time-start_time)\n",
    "        output_mat = out_buffer[8:].reshape(batch_size, -1).astype(np.float32)\n",
    "        for i in range(batch_size):\n",
    "            output_mat[i] = output_mat[i]/sum(output_mat[i])\n",
    "        return output_mat\n",
    "\n",
    "    @staticmethod\n",
    "    def checkhierarchy(description):\n",
    "        if 'axi_dma_0' in description['ip']:\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# input image dimensions\n",
    "num_classes = 10\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('int16')\n",
    "x_test = x_test.astype('int16')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('mnist_mlp_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay = Overlay('mlp.bit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weight = model.get_layer(0, 0).get_weights()\n",
    "weight = np.transpose(weight)\n",
    "overlay.memory.loadweight(weight, 1, 1, 1, 0)\n",
    "weight = model.get_layer(0, 1).get_weights()\n",
    "weight = np.transpose(weight)\n",
    "overlay.memory.loadweight(weight, 2, 1, 1, 0)\n",
    "weight = model.get_layer(0, 2).get_weights()\n",
    "weight = np.transpose(weight)\n",
    "overlay.memory.loadweight(weight, 3, 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Test Time:  0.35225220899999954\n",
      "FPGA accuracy: 0.96\n",
      "CPU times: user 580 ms, sys: 10 ms, total: 590 ms\n",
      "Wall time: 591 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "count = 0\n",
    "batch_size = 100\n",
    "result = overlay.memory.execute(x_test, batch_size)\n",
    "for i in range(batch_size):\n",
    "    if result[i].argmax() == y_test[i].argmax():\n",
    "        count = count + 1\n",
    "score = count/batch_size\n",
    "print('FPGA accuracy:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arm accuracy: 0.96\n",
      "CPU times: user 60 ms, sys: 0 ns, total: 60 ms\n",
      "Wall time: 56 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "count = 0\n",
    "result = model.predict(x_test[0:batch_size])\n",
    "for i in range(batch_size):\n",
    "    if result[i].argmax() == y_test[i].argmax():\n",
    "        count = count + 1\n",
    "score = count/batch_size\n",
    "print('Arm accuracy:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 681us/step\n",
      "Arm accuracy: 0.96\n",
      "CPU times: user 70 ms, sys: 10 ms, total: 80 ms\n",
      "Wall time: 79.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score = model.evaluate(x_test[0:batch_size], y_test[0:batch_size])\n",
    "print('Arm accuracy:', score[1].astype(np.float32))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
