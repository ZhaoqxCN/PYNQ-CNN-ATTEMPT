{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 工具包导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import keras\n",
    "import numpy as np\n",
    "import fpga_drive\n",
    "import matplotlib.pyplot as plt\n",
    "from pynq import Overlay\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 准备图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7545 images belonging to 8 classes.\n",
      "x_test shape: (512, 256, 256, 1)\n",
      "512 test samples\n"
     ]
    }
   ],
   "source": [
    "num_classes = 8\n",
    "quant_scale = 256\n",
    "classlist = ['A2C', 'A3C', 'A4C', 'ASA', 'BSA', 'MSA', 'PLA', 'PSA']\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rescale=127\n",
    ")\n",
    "val_generator = val_datagen.flow_from_directory(directory='data',\n",
    "                                                target_size=(256, 256),\n",
    "                                                color_mode='grayscale',\n",
    "                                                batch_size=512,\n",
    "                                                shuffle=False)\n",
    "[x_test, y_test] = val_generator[4]\n",
    "print('x_test shape:', x_test.shape)\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 读取网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('ultrasound.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 63, 63, 16)        416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 21, 21, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 9, 9, 32)          12832     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 5, 5, 32)          18464     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 3, 16)          4624      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 144)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               18560     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 74,424\n",
      "Trainable params: 74,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 配置FPGA Overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay = Overlay(\"ultra.bit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 配置HDMI端口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "overlay.video.configure(800, 600, 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 加载网络权值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = model.get_layer('conv2d_1').get_weights()\n",
    "overlay.cnn.load_weight_conv(weight, 1, quant_scale, 0.95)\n",
    "weight = model.get_layer('conv2d_2').get_weights()\n",
    "overlay.cnn.load_weight_conv(weight, 2, quant_scale, 1.25)\n",
    "weight = model.get_layer('conv2d_3').get_weights()\n",
    "overlay.cnn.load_weight_conv(weight, 3, quant_scale, 1.6)\n",
    "weight = model.get_layer('conv2d_4').get_weights()\n",
    "overlay.cnn.load_weight_conv(weight, 4, quant_scale, 1.3)\n",
    "weight = model.get_layer('conv2d_5').get_weights()\n",
    "overlay.cnn.load_weight_conv(weight, 5, quant_scale, 1.75)\n",
    "weight = model.get_layer('dense_1').get_weights()\n",
    "overlay.cnn.load_weight_fc(weight, 6, quant_scale, 1.6)\n",
    "weight = model.get_layer('dense_2').get_weights()\n",
    "overlay.cnn.load_weight_fc(weight, 7, quant_scale, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 运算一个Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Test Time:  252.59957799998745 ms\n",
      "FPAG Elapsed Test Time:  852.3827820000065 ms\n",
      "FPGA accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "batch_size = 100\n",
    "start_time = time.process_time()\n",
    "result = overlay.cnn.execute(x_test, batch_size, 1, 256, 8, 1)\n",
    "end_time = time.process_time()\n",
    "print(\"FPAG Elapsed Test Time: \", (end_time-start_time)*1000, \"ms\")\n",
    "for i in range(batch_size):\n",
    "    if result[i].argmax() == y_test[i].argmax():\n",
    "        count = count + 1\n",
    "score = count/batch_size\n",
    "print('FPGA accuracy:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arm Elapsed Test Time:  6716.667694999998 ms\n",
      "Arm accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "batch_size = 100\n",
    "start_time = time.process_time()\n",
    "result = model.predict(x_test[0:batch_size])\n",
    "end_time = time.process_time()\n",
    "print(\"Arm Elapsed Test Time: \", (end_time-start_time)*1000, \"ms\")\n",
    "for i in range(batch_size):\n",
    "    if result[i].argmax() == y_test[i].argmax():\n",
    "        count = count + 1\n",
    "score = count/batch_size\n",
    "print('Arm accuracy:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 循环展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x_test, y_test] = val_generator[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "for index in range(batch_size):\n",
    "    result = overlay.cnn.execute_s(x_test[index], 1, 256, 8, 1)\n",
    "    img = x_test[index] + 127\n",
    "    img = cv2.resize(img, (800, 600)).astype(np.uint8)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    img = cv2.putText(img, classlist[result.argmax()], (600, 100), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 255, 255), 2)\n",
    "    overlay.video.display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "for index in range(batch_size):\n",
    "    result = overlay.cnn.execute_s(x_test[index], 1, 256, 8, 1)\n",
    "    img = x_test[index] + 127\n",
    "    img = cv2.resize(img, (800, 600)).astype(np.uint8)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    img = cv2.putText(img, classlist[y_test[index].argmax()], (600, 100), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 255, 255), 2)\n",
    "    overlay.video.display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试网络全局准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7545 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "val_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rescale=127\n",
    ")\n",
    "val_generator = val_datagen.flow_from_directory(directory='data',\n",
    "                                                target_size=(256, 256),\n",
    "                                                color_mode='grayscale',\n",
    "                                                batch_size=256,\n",
    "                                                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Test Time:  572.1692669999925 ms\n",
      "Elapsed Test Time:  489.31970399999614 ms\n",
      "Elapsed Test Time:  641.0400209999807 ms\n",
      "Elapsed Test Time:  640.8378200000016 ms\n",
      "Elapsed Test Time:  640.9172330000388 ms\n",
      "Elapsed Test Time:  640.904565000028 ms\n",
      "Elapsed Test Time:  640.8796729999722 ms\n",
      "Elapsed Test Time:  640.954445000034 ms\n",
      "Elapsed Test Time:  640.8238629999801 ms\n",
      "Elapsed Test Time:  640.8981339999968 ms\n",
      "Elapsed Test Time:  640.8398140000031 ms\n",
      "Elapsed Test Time:  640.9148310000319 ms\n",
      "Elapsed Test Time:  640.8896570000024 ms\n",
      "Elapsed Test Time:  640.7979869999849 ms\n",
      "Elapsed Test Time:  640.9772089999706 ms\n",
      "Elapsed Test Time:  641.0089770000127 ms\n",
      "Elapsed Test Time:  640.9293680000019 ms\n",
      "Elapsed Test Time:  640.6825860000254 ms\n",
      "Elapsed Test Time:  639.9308109999993 ms\n",
      "Elapsed Test Time:  640.6457249999562 ms\n",
      "Elapsed Test Time:  640.7502019999924 ms\n",
      "Elapsed Test Time:  640.7829030000016 ms\n",
      "Elapsed Test Time:  640.7291030000124 ms\n",
      "Elapsed Test Time:  640.9000099999957 ms\n",
      "Elapsed Test Time:  640.7679859999007 ms\n",
      "Elapsed Test Time:  640.6771389999903 ms\n",
      "Elapsed Test Time:  640.8881109999811 ms\n",
      "Elapsed Test Time:  640.7893980000381 ms\n",
      "Elapsed Test Time:  640.6236049999734 ms\n",
      "FPGA accuracy: 0.7887342611000663\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for j in range(29):\n",
    "    [x_test, y_test] = val_generator[j]\n",
    "    batch_size = x_test.shape[0]\n",
    "    result = overlay.cnn.execute(x_test, batch_size, 1, 256, 8, 1)\n",
    "    for i in range(batch_size):\n",
    "        if result[i].argmax() == y_test[i].argmax():\n",
    "            count = count + 1\n",
    "score = count/7545\n",
    "print('FPGA accuracy:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 557s 19s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8160371107996656"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate_generator(val_generator, verbose=1)\n",
    "score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置单层权值\n",
    "# x=[1,2,3,4,5,6,7,8,9]\n",
    "# x = np.transpose(x)\n",
    "# x=np.reshape(x,(1,3,3,1,1))\n",
    "# model.get_layer('conv2d_1').set_weights(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取中间结果\n",
    "# intermediate_layer_model = Model(inputs=model.input,\n",
    "#                                  outputs=model.get_layer('conv2d_1').output)\n",
    "# pre = intermediate_layer_model.predict(x_test[0].reshape(1,256,256,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 展示图片\n",
    "# result = np.reshape(x_test[0], (256,256))\n",
    "# plt.figure(figsize=(4, 4))\n",
    "# plt.imshow(result, 'gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
